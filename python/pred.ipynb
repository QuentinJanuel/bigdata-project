{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPLE TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "csv_anime = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"../csv/data.csv\")\\\n",
    "    .withColumn(\"score\", col(\"score\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler()\\\n",
    "    .setInputCols([col for col in csv_anime.columns if col != \"score\"])\\\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "data_df = assembler\\\n",
    "    .transform(csv_anime)\\\n",
    "    .select(\"features\", \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import (\n",
    "    DecisionTreeRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GBTRegressor,\n",
    ")\n",
    "\n",
    "print(\"Decision Tree Regressor\")\n",
    "model_tree = DecisionTreeRegressor()\\\n",
    "    .setLabelCol(\"score\")\\\n",
    "    .setFeaturesCol(\"features\")\\\n",
    "    .fit(train_df)\n",
    "\n",
    "print(\"Random Forest Regressor\")\n",
    "model_random_forest = RandomForestRegressor()\\\n",
    "    .setLabelCol(\"score\")\\\n",
    "    .setFeaturesCol(\"features\")\\\n",
    "    .setNumTrees(10)\\\n",
    "    .fit(train_df)\n",
    "\n",
    "print(\"Gradient Boosted Tree Regressor\")\n",
    "model_gbt = GBTRegressor()\\\n",
    "    .setLabelCol(\"score\")\\\n",
    "    .setFeaturesCol(\"features\")\\\n",
    "    .fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tree = model_tree.transform(test_df)\n",
    "predictions_random_forest = model_random_forest.transform(test_df)\n",
    "predictions_gbt = model_gbt.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: rmse = 3.044417074181475\n",
      "Random forest: rmse = 3.0435001772367203\n",
      "Gradient Boosted Tree: rmse = 2.9433101966278787\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"score\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\",\n",
    ")\n",
    "\n",
    "error_tree = evaluator.evaluate(predictions_tree)\n",
    "print(f\"Decision tree: rmse = {error_tree}\")\n",
    "\n",
    "error_random_forest = evaluator.evaluate(predictions_random_forest)\n",
    "print(f\"Random forest: rmse = {error_random_forest}\")\n",
    "\n",
    "error_gbt = evaluator.evaluate(predictions_gbt)\n",
    "print(f\"Gradient Boosted Tree: rmse = {error_gbt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATRIX FACTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "csv_anime = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"../csv/data2.csv\")\\\n",
    "    .withColumn(\"rating\", col(\"rating\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = csv_anime.rdd.map(lambda row: Rating(row.user, row.product, row.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(ratings, rank, numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = ratings.map(lambda p: (p[0], p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "RMSE = math.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.30479637608477866\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \" + str(RMSE))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5474208bf1f0a06244c45194a981d3a26092aeeabac10f018062612a4ec2037"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
